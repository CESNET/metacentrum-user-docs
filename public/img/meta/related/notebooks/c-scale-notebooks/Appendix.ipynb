{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9276bb19-7ea5-4a38-9bb6-a04fb040203b",
   "metadata": {},
   "source": [
    "# Appendix: Sentinel-2 satellite image analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f256c0-7099-48d3-b45c-ca78b7e67611",
   "metadata": {},
   "source": [
    "This notebook intends to show couple ideas how to analyse satellite images using different spectral bands and visualising the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e368f3-369d-4d28-95da-36685fac8e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from cscale_notebooks_functions import load_sentinel_image, display_rgb, image_rgb, normalized_difference, plot_masked_rgb, resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d4ee15-251a-4f42-97b9-f669d8d7c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose folder where are your downloaded satelite images  \n",
    "img_folder = \"/images/clipped/\"\n",
    "path = os.path.abspath(\"\")\n",
    "folder_img = path + img_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bf9b51-0773-4964-a875-a107f7930b2b",
   "metadata": {},
   "source": [
    "Different channels has different resolution, so it needs to be resampled in order to be able to put them together. You can check the channel resolution [here](https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-2-msi/resolutions/spatial).\n",
    "\n",
    "In case of L1C data we need to resample channels B05, B06, B11 and B12 with the factor of 2 and B09 with factor 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6015065f-19ad-42a0-9f8b-348a60ffa0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_temp = \"B02.tif\"\n",
    "file_res = [\"B05.tif\", \"B06.tif\", \"B11.tif\", \"B12.tif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab014a8-c568-419d-9e67-351a7812c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(file_res)):\n",
    "    resampled = resampling(folder_img,file_temp,file_res[n],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f76fbc-d431-4764-ae28-8045fdfd7109",
   "metadata": {},
   "source": [
    "##### NOTE: In case of L1C data the channel B09 is resampled with factor of 6, whereas L2A data needs resampling of ONLY channel B09 with the factor of 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200cba87-ec91-44dd-9242-f69c3b324120",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_temp = \"B02.tif\"\n",
    "file_res = [\"B09.tif\", \"B10.tif\"]\n",
    "\n",
    "for n in range(len(file_res)):\n",
    "    resampled_09 = resampling(folder_img,file_temp,file_res[n],6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb7f39f-8375-4163-bbbf-0126f0b9879e",
   "metadata": {},
   "source": [
    "##### NOTE: In case of L1C data we need to enter B05_res, B06_res channels. For L2A just B05 and B06."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ae8637-2d45-445c-a5ba-e642abfe200d",
   "metadata": {},
   "source": [
    "We can compute spectral index using different bands. In this notebook we calculate Normalized Difference (ND) index using custom function. ND index is defined as:\n",
    "\n",
    "$$ \n",
    "ND = (Band1 - Band2)/ (Band1 + Band2) \n",
    "$$\n",
    "\n",
    "Here we calculate two indexes, where different areas are emphasized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62610c70-893c-4202-8a33-a39051155820",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = load_sentinel_image(folder_img, [\"B02\", \"B03\", \"B04\"])\n",
    "img_nir = load_sentinel_image(folder_img, [\"B03\", \"B04\", \"B06_res\"])\n",
    "img_nir2 = load_sentinel_image(folder_img, [\"B03\", \"B04\", \"B08\"])\n",
    "\n",
    "rgb = image_rgb(img_rgb, 'B04', 'B03', 'B02', alpha=5.)\n",
    "nir = image_rgb(img_nir, 'B06_res', 'B04', 'B03', alpha=5.)\n",
    "\n",
    "# Calculating two indices\n",
    "ndvi = normalized_difference(img_nir2, 'B08', 'B04')\n",
    "mndwi = normalized_difference(img_nir2, 'B03', 'B08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5068f52e-17a1-471f-8f04-c9a87f31ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# checking the images\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "fontsize=16\n",
    "ax = ax.flatten()\n",
    "\n",
    "ax[0].imshow((rgb*255).astype(np.uint8), interpolation='none')\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Color Image', fontsize=fontsize)\n",
    "\n",
    "ax[1].imshow((nir*255).astype(np.uint8), interpolation='none')\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('NIR', fontsize=fontsize)\n",
    "\n",
    "ax[2].imshow(ndvi, cmap='Greens', interpolation='none')\n",
    "ax[2].axis('off')\n",
    "ax[2].set_title('NDVI', fontsize=fontsize)\n",
    "\n",
    "ax[3].imshow(mndwi, cmap='Blues', interpolation='none') # * 255).astype(np.uint8)\n",
    "ax[3].axis('off')\n",
    "ax[3].set_title('MNDWI', fontsize=fontsize)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc615e57-e605-4e9e-a9bb-17c18eb56b09",
   "metadata": {},
   "source": [
    "Colour image is a true colour image, what one can observe for example from a plane. NIR image is more sensitive to different kind of vegetation and water areas. NDVI index gives a better response (higher values = greener because of the colormap we applied) over the vegetation areas and the MNDWI has a higher response (higher values = bluer because of the ‘Blues’ colormap) for water areas like rivers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c743739-8c4b-4520-aafa-ee5dc97c61ed",
   "metadata": {},
   "source": [
    "### We can play more with the bands and their order while displaying.\n",
    "\n",
    "In case of L1C data we need to enter B12_res and B11_res. L2A just B12 and B11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0042d12-74b2-47f8-91d7-2c4d606bea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_sentinel_image(folder_img, [\"B03\", \"B04\", \"B12_res\"])\n",
    "rgb = image_rgb(img, 'B12_res', 'B03', 'B04', alpha=5.)\n",
    "bgr = image_rgb(img, 'B04', 'B12_res', 'B03', alpha=5.)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 10))\n",
    "ax[0].imshow((rgb* 255).astype(np.uint8), cmap='Greens')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow((bgr* 255).astype(np.uint8), cmap='Blues')\n",
    "ax[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce53e9-1b58-4fd6-84cc-623c061d9f2e",
   "metadata": {},
   "source": [
    "### We can look for parks, water surfaces or buildings in city area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a7376-bcb8-41c6-86b4-aac9f6ed1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cscale_notebooks_functions import clipper, coor_converter\n",
    "coor_converter(\"geojson/prague.geojson\",\"geojson/prague_GPScut.geojson\",32633)\n",
    "Prague_reg = \"geojson/prague_GPScut.geojson\"\n",
    "\n",
    "roicut_path = path + \"/images/cut_out/\"\n",
    "if os.path.isdir(roicut_path) != True:\n",
    "    os.mkdir(roicut_path)\n",
    "\n",
    "clipper(folder_img, Prague_reg, roicut_path, whole = \"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c0c75a-3432-426f-95c1-bd6abe2c0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_sentinel_image(roicut_path, [\"B03\", \"B04\", \"B09_res\"])\n",
    "img1 = load_sentinel_image(roicut_path, [\"B03\", \"B04\", \"B09_res\"])\n",
    "rgb = image_rgb(img, 'B03', 'B04', 'B09_res', alpha=5.5)\n",
    "bgr = image_rgb(img1, 'B04', 'B09_res', 'B03', alpha=5.5)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize= (15, 10))\n",
    "ax[0].imshow((rgb* 255).astype(np.uint8))\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow((bgr* 255).astype(np.uint8))\n",
    "ax[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf2784-a853-49c8-87d9-64c9a95b8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = normalized_difference(img,'B09_res','B03',)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(diff, cmap = 'Greens_r')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60788375-a451-46d2-b6d6-c67b121c72b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
